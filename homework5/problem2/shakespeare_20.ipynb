{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import requests\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Step 1: Download the dataset\n",
    "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "response = requests.get(url)\n",
    "text = response.text  # This is the entire text data\n",
    "\n",
    "# Creating character vocabulary\n",
    "chars = sorted(list(set(text)))\n",
    "ix_to_char = {i: ch for i, ch in enumerate(chars)}\n",
    "char_to_ix = {ch: i for i, ch in enumerate(chars)}\n",
    "\n",
    "# Preparing the dataset\n",
    "max_length = 20  # Maximum length of input sequences\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(len(text) - max_length):\n",
    "    sequence = text[i:i + max_length]\n",
    "    label = text[i + max_length]\n",
    "    X.append([char_to_ix[char] for char in sequence])\n",
    "    y.append(char_to_ix[label])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Splitting the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Converting data to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.long)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "X_val = torch.tensor(X_val, dtype=torch.long)\n",
    "y_val = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "# Defining the Transformer model\n",
    "class CharTransformer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, nhead):\n",
    "        super(CharTransformer, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(hidden_size, nhead, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        transformer_output = self.transformer_encoder(embedded)\n",
    "        output = self.fc(transformer_output[:, -1, :])  # Get the output of the last Transformer block\n",
    "        return output\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[51, 57,  1, 51, 39, 49, 43,  1, 51, 43, 52,  1, 43, 62, 54, 43, 41, 58,\n",
      "          1, 39],\n",
      "        [ 1, 51, 53, 60, 43,  1, 51, 43, 52, 11,  1, 40, 43, 57, 47, 42, 43,  6,\n",
      "          1, 57],\n",
      "        [47, 40, 39, 50, 57,  0, 35, 53, 59, 50, 42,  1, 52, 53, 58,  1, 46, 39,\n",
      "         60, 43],\n",
      "        [57,  1, 42, 56, 53, 61, 52,  1, 58, 46, 43, 47, 56,  1, 57, 46, 53, 56,\n",
      "         43, 57],\n",
      "        [ 1, 58, 46, 63,  1, 50, 53, 56, 42,  6,  1, 58, 46, 63,  1, 49, 47, 52,\n",
      "         45,  6],\n",
      "        [43, 43, 42,  1, 44, 56, 47, 43, 52, 42, 57, 10,  1, 57, 59, 40, 48, 43,\n",
      "         41, 58],\n",
      "        [43, 56,  1, 63, 53, 59, 56,  1, 45, 56, 39, 60, 47, 58, 63,  1, 53,  5,\n",
      "         43, 56],\n",
      "        [18,  1, 13, 33, 25, 17, 30, 24, 17, 10,  0, 20, 43,  1, 51, 43, 39, 52,\n",
      "         57,  6],\n",
      "        [44,  1, 51, 43,  8,  0,  0, 28, 17, 32, 30, 33, 15, 20, 21, 27, 10,  0,\n",
      "         37, 53],\n",
      "        [63,  1,  5, 52, 53,  5,  1, 58, 53,  1, 51, 63,  1, 42, 43, 51, 39, 52,\n",
      "         42,  8]])\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_loader:\n",
    "    print(inputs[:10])\n",
    "    #print(targets[:10])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.8292577266693115, Validation Loss: 2.3859910989416377, Validation Accuracy: 0.29618175081562464\n",
      "Epoch 2, Loss: 2.8695273399353027, Validation Loss: 2.3518227858920926, Validation Accuracy: 0.30523731832232753\n",
      "Epoch 3, Loss: 2.3850204944610596, Validation Loss: 2.331058119554596, Validation Accuracy: 0.31009006263432803\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "hidden_size = 16\n",
    "num_layers = 2\n",
    "nhead = 2\n",
    "learning_rate = 0.001\n",
    "epochs = 15\n",
    "\n",
    "# Model, loss, and optimizer\n",
    "model = CharTransformer(len(chars), hidden_size, len(chars), num_layers, nhead).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training the model\n",
    "for epoch in range(epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(inputs)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    total_val_accuracy = 0\n",
    "    num_batches = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)        \n",
    "            val_output = model(inputs)\n",
    "            val_loss = criterion(val_output, labels)\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "            _, predicted = torch.max(val_output, 1)\n",
    "            val_accuracy = (predicted == labels).float().mean()\n",
    "            total_val_accuracy += val_accuracy.item()\n",
    "            num_batches += 1\n",
    "               \n",
    "    average_val_loss = total_val_loss / num_batches\n",
    "    average_val_accuracy = total_val_accuracy / num_batches\n",
    "\n",
    "    if (epoch+1) % 1 == 0:\n",
    "     print(f'Epoch {epoch+1}, Loss: {loss.item()}, Validation Loss: {average_val_loss}, Validation Accuracy: {average_val_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Predicting the next character\u001b[39;00m\n\u001b[1;32m     20\u001b[0m test_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is a simple example to demonstrate how to predict the next char\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 21\u001b[0m predicted_char \u001b[38;5;241m=\u001b[39m predict_next_char(\u001b[43mmodel\u001b[49m, char_to_ix, ix_to_char, test_str, max_length)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted next character: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_char\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Prediction function\n",
    "def predict_next_char(model, char_to_ix, ix_to_char, initial_str, max_length):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Ensure the input is not shorter than expected\n",
    "        if len(initial_str) < max_length:\n",
    "            initial_str = (' ' * (max_length - len(initial_str))) + initial_str\n",
    "        \n",
    "        # Convert characters to indices, handling characters not in the dictionary\n",
    "        initial_indices = [char_to_ix.get(c, char_to_ix[' ']) for c in initial_str[-max_length:]]\n",
    "        \n",
    "        initial_input = torch.tensor(initial_indices, dtype=torch.long).unsqueeze(0).to(device)\n",
    "        prediction = model(initial_input)\n",
    "        last_timestep_pred = prediction.squeeze(0)[-1]\n",
    "        predicted_index = torch.argmax(last_timestep_pred, dim=0).item()\n",
    "        return ix_to_char[predicted_index]\n",
    "\n",
    "# Predicting the next character\n",
    "test_str = \"This is a simple example to demonstrate how to predict the next char\"\n",
    "predicted_char = predict_next_char(model, char_to_ix, ix_to_char, test_str, max_length)\n",
    "print(f\"Predicted next character: '{predicted_char}'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
